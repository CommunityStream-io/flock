# Vercel Blob Storage Integration

## Overview

Flock Murmur uses Vercel Blob storage for handling large Instagram archive files. This provides better scalability and performance compared to storing large files in Vercel KV.

## Architecture

```
Client Upload ‚Üí Vercel Edge Function ‚Üí Vercel Blob Storage
                         ‚Üì
                  Metadata in KV (session, filename, blobUrl)
                         ‚Üì
Migration Process ‚Üí Fetch from Blob ‚Üí Process Archive
```

## Why Blob Storage?

### Advantages over KV Storage

| Feature | Vercel Blob | Vercel KV |
|---------|-------------|-----------|
| **File Size Limit** | Up to 500MB | Limited by value size |
| **Optimized For** | Large binary files | Small key-value data |
| **Access Speed** | Fast CDN-backed | Very fast in-memory |
| **Best Use Case** | Archive storage | Metadata & sessions |
| **Cost** | Per GB stored | Per operation |

### Our Implementation

- **Blob Storage**: Stores actual ZIP archives
- **KV Storage**: Stores metadata (sessionId, filename, blobUrl, etc.)
- **Combined Benefits**: Fast metadata lookup + efficient large file storage

## Configuration

### Environment Variables

Vercel Blob requires these environment variables (automatically configured in Vercel):

```bash
BLOB_READ_WRITE_TOKEN=<auto-generated>
```

### Package Dependencies

```json
{
  "dependencies": {
    "@vercel/blob": "^0.19.0"
  }
}
```

## API Implementation

### Upload Endpoint (`/api/upload`)

```typescript
import { put } from '@vercel/blob';

// Upload file to Blob
const blob = await put(
  `archives/${sessionId}/${filename}`,
  fileBuffer,
  {
    access: 'public',
    addRandomSuffix: false
  }
);

// Store metadata in KV
await kv.set(`upload:${sessionId}`, {
  sessionId,
  filename,
  size,
  blobUrl: blob.url,  // URL to retrieve file
  uploadedAt: new Date().toISOString()
}, {
  ex: 3600  // 1 hour TTL
});
```

### Migration Endpoint (`/api/migrate`)

```typescript
// Get metadata from KV
const uploadMeta = await kv.get(`upload:${sessionId}`);
const blobUrl = uploadMeta.blobUrl;

// Fetch file from Blob storage
const response = await fetch(blobUrl);
const archiveBuffer = Buffer.from(await response.arrayBuffer());

// Process the archive
const processor = new InstagramArchiveProcessor(sessionId, archiveBuffer);
```

## Blob Storage Features

### File Organization

Archives are stored with the following path structure:

```
archives/
  ‚îî‚îÄ‚îÄ {sessionId}/
      ‚îî‚îÄ‚îÄ {filename}
```

Example:
```
archives/upload_1234567890_abc123/instagram-archive.zip
```

### Access Control

- **Access Level**: Public (temporary URLs)
- **TTL**: Files automatically expire after 1 hour (managed via KV metadata)
- **Cleanup**: Manual cleanup after migration completes

### File Size Limits

| Plan | Upload Limit | Storage Limit |
|------|--------------|---------------|
| Free (Hobby) | 500MB per file | 1GB total |
| Pro | 500MB per file | Unlimited |
| Enterprise | Custom | Unlimited |

## Usage Flow

### 1. Client Upload

```typescript
// Client side
const formData = new FormData();
formData.append('archive', file);

const response = await fetch('/api/upload', {
  method: 'POST',
  body: formData
});

const { sessionId } = await response.json();
```

### 2. Server Storage

```typescript
// Server side - upload.ts
const blob = await put(`archives/${sessionId}/${filename}`, fileBuffer, {
  access: 'public',
  addRandomSuffix: false
});

// Returns: { url: 'https://blob.vercel-storage.com/...' }
```

### 3. Migration Processing

```typescript
// Server side - migrate.ts
const uploadMeta = await kv.get(`upload:${sessionId}`);
const response = await fetch(uploadMeta.blobUrl);
const archiveBuffer = Buffer.from(await response.arrayBuffer());

// Process archive...
```

### 4. Cleanup

Files are automatically cleaned up through TTL:
- KV metadata expires in 1 hour
- Blob files should be manually deleted after successful migration

## Error Handling

### Upload Errors

```typescript
try {
  const blob = await put(path, fileBuffer, options);
} catch (error) {
  if (error.code === 'BLOB_UPLOAD_FAILED') {
    // Handle upload failure
  }
  if (error.code === 'FILE_TOO_LARGE') {
    // File exceeds 500MB limit
  }
}
```

### Download Errors

```typescript
const response = await fetch(blobUrl);
if (!response.ok) {
  // Handle fetch failure
  throw new Error('Failed to download from Blob storage');
}
```

## Best Practices

### 1. Always Store Metadata

```typescript
// ‚úÖ Good - Store metadata in KV
await kv.set(`upload:${sessionId}`, {
  blobUrl: blob.url,
  filename,
  size,
  uploadedAt: new Date().toISOString()
});
```

### 2. Validate Before Processing

```typescript
// ‚úÖ Good - Validate metadata exists
const uploadMeta = await kv.get(`upload:${sessionId}`);
if (!uploadMeta || !uploadMeta.blobUrl) {
  throw new Error('Upload not found');
}
```

### 3. Clean Up After Processing

```typescript
// ‚úÖ Good - Delete after successful migration
// TODO: Implement cleanup after migration completes
```

### 4. Handle Large Files Efficiently

```typescript
// ‚úÖ Good - Stream processing for very large files
const response = await fetch(blobUrl);
const reader = response.body.getReader();
// Process in chunks...
```

## Monitoring

### Check Blob Usage

```bash
# Via Vercel Dashboard
# Navigate to: Storage ‚Üí Blob ‚Üí Usage
```

### Logs to Monitor

```typescript
console.log('[Upload] File uploaded to Blob:', blob.url);
console.log('[Migrate] Fetching from Blob:', blobUrl);
console.log('[Migrate] Archive size:', buffer.length);
```

## Troubleshooting

### Issue: Upload fails with "File too large"

**Solution**: Files must be under 500MB. Split or compress larger archives.

### Issue: "Blob URL not found"

**Solution**: Ensure metadata is properly stored in KV after upload.

```typescript
// Check metadata
const meta = await kv.get(`upload:${sessionId}`);
console.log('Metadata:', meta);
```

### Issue: Fetch from Blob fails

**Solution**: Verify blob URL is accessible and not expired.

```typescript
// Test blob URL
const response = await fetch(blobUrl);
console.log('Blob accessible:', response.ok);
```

## Migration from KV to Blob

### Old Approach (KV only)

```typescript
// ‚ùå Old - Stored in KV as base64
await kv.set(`upload:data:${sessionId}`, 
  fileBuffer.toString('base64')
);
```

### New Approach (Blob + KV)

```typescript
// ‚úÖ New - File in Blob, metadata in KV
const blob = await put(`archives/${sessionId}/${filename}`, fileBuffer);
await kv.set(`upload:${sessionId}`, {
  blobUrl: blob.url,
  filename,
  size
});
```

## Cost Optimization

### Free Tier Limits

- **Storage**: 1GB total
- **Bandwidth**: Limited
- **Best Practice**: Clean up files after processing

### Upgrade Considerations

Upgrade to Pro if you need:
- More than 1GB storage
- Higher bandwidth
- Longer retention periods

## Security

### Access Control

- Blob URLs are public but hard to guess (cryptographic randomness)
- URLs expire through metadata TTL
- No authentication required for download (session-based access control)

### Data Privacy

- Archives contain user data - handle with care
- Automatic cleanup after 1-2 hours
- No long-term storage

## Future Enhancements

### Potential Improvements

1. **Automatic Cleanup**: Delete blobs after successful migration
2. **Streaming Upload**: Support for very large files via streams
3. **Compression**: Pre-compress archives before storage
4. **CDN Optimization**: Leverage Vercel's CDN for faster downloads
5. **Multipart Upload**: Support for files larger than 500MB

---

*Efficient large file storage with Vercel Blob! üåä‚ú®*
